# =============================================================================
# CONFIGURACION DE OLLAMA
# =============================================================================

# Version de Ollama
OLLAMA_VERSION=latest

# Modelo a descargar automaticamente al iniciar
# Opciones populares:
#   - llama3.2:1b      (1.3GB, rapido, CPU friendly)
#   - llama3.2:3b      (2GB, buen balance)
#   - llama3.1:8b      (4.7GB, muy capaz)
#   - mistral:7b       (4.1GB, muy bueno)
#   - codellama:7b     (3.8GB, para codigo)
#   - phi3:mini        (2.3GB, Microsoft, rapido)
#   - gemma2:2b        (1.6GB, Google, rapido)
#   - qwen2.5:7b       (4.7GB, Alibaba, multilingue)
#
# Dejar vacio para no descargar nada automaticamente
OLLAMA_MODEL=llama3.2:1b

# GPU: true/false
# Si true, asegurate de tener nvidia-container-toolkit instalado
OLLAMA_GPU=false
